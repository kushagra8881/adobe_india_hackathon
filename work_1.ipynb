{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b2f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cfe6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('output_outline_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22248aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>level</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>Revision History</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>Table of Contents</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>Acknowledgements</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>1. Introduction to the Foundation Level Extens...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>2. Introduction to Foundation Level Agile Test...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H3</td>\n",
       "      <td>Social Media Campaigns</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H3</td>\n",
       "      <td>Influencer Partnerships</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H2</td>\n",
       "      <td>Traditional Marketing</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H1</td>\n",
       "      <td>Budget Allocation</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H1</td>\n",
       "      <td>Performance Metrics</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file                                    title level  \\\n",
       "0    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "1    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "2    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "3    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "4    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "..               ...                                      ...   ...   \n",
       "166  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H3   \n",
       "167  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H3   \n",
       "168  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H2   \n",
       "169  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H1   \n",
       "170  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H1   \n",
       "\n",
       "                                                  text  page  \n",
       "0                                    Revision History      2  \n",
       "1                                   Table of Contents      3  \n",
       "2                                    Acknowledgements      4  \n",
       "3    1. Introduction to the Foundation Level Extens...     5  \n",
       "4    2. Introduction to Foundation Level Agile Test...     6  \n",
       "..                                                 ...   ...  \n",
       "166                             Social Media Campaigns     7  \n",
       "167                            Influencer Partnerships     8  \n",
       "168                              Traditional Marketing     9  \n",
       "169                                  Budget Allocation    10  \n",
       "170                                Performance Metrics    12  \n",
       "\n",
       "[171 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db13ad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (171, 5)\n",
      "\n",
      "Column names: ['file', 'title', 'level', 'text', 'page']\n",
      "\n",
      "Unique levels: ['H1' 'H2' 'H3' 'H4']\n",
      "\n",
      "Level counts:\n",
      "level\n",
      "H2    72\n",
      "H1    59\n",
      "H3    36\n",
      "H4     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few rows:\n",
      "              file                                    title level  \\\n",
      "0  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "1  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "2  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "3  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "4  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "\n",
      "                                                text  page  \n",
      "0                                  Revision History      2  \n",
      "1                                 Table of Contents      3  \n",
      "2                                  Acknowledgements      4  \n",
      "3  1. Introduction to the Foundation Level Extens...     5  \n",
      "4  2. Introduction to Foundation Level Agile Test...     6  \n"
     ]
    }
   ],
   "source": [
    "# Check data structure and unique levels\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"\\nColumn names:\", data.columns.tolist())\n",
    "print(\"\\nUnique levels:\", data['level'].unique())\n",
    "print(\"\\nLevel counts:\")\n",
    "print(data['level'].value_counts())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99561f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08770719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for Random Forest classification...\n",
      "Cleaned data shape: (166, 6)\n",
      "Level distribution after cleaning:\n",
      "level\n",
      "H2    70\n",
      "H1    57\n",
      "H3    35\n",
      "H4     4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2672484/1276247304.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['combined_text'] = data_clean['title'].astype(str) + ' ' + data_clean['text'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and feature engineering\n",
    "print(\"Preparing data for Random Forest classification...\")\n",
    "\n",
    "# Clean and prepare the data\n",
    "data_clean = data.dropna(subset=['title', 'text', 'level'])\n",
    "\n",
    "# Combine title and text for feature extraction\n",
    "data_clean['combined_text'] = data_clean['title'].astype(str) + ' ' + data_clean['text'].astype(str)\n",
    "\n",
    "# Remove empty or very short texts\n",
    "data_clean = data_clean[data_clean['combined_text'].str.len() > 3]\n",
    "\n",
    "print(f\"Cleaned data shape: {data_clean.shape}\")\n",
    "print(f\"Level distribution after cleaning:\")\n",
    "print(data_clean['level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cf11171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features using TF-IDF with multilingual support...\n",
      "Feature matrix shape: (166, 1593)\n",
      "Target variable shape: (166,)\n",
      "Vectorizer encoding: utf-8\n",
      "Vectorizer analyzer: char_wb\n",
      "Training set size: 149\n",
      "Testing set size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushagra/Documents/code/AI/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:555: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction using TF-IDF with multilingual UTF-8 support\n",
    "print(\"Extracting features using TF-IDF with multilingual support...\")\n",
    "\n",
    "# Create TF-IDF features from combined text with UTF-8 and multilingual support\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,  # Increased for multilingual content\n",
    "    ngram_range=(1, 3),  # Use unigrams, bigrams, and trigrams for better multilingual support\n",
    "    min_df=1,  # Reduced to handle diverse languages\n",
    "    max_df=0.9,  # Slightly increased threshold\n",
    "    lowercase=True,  # Convert to lowercase for consistency\n",
    "    analyzer='char_wb',  # Character-based analysis for multilingual support\n",
    "    encoding='utf-8',  # Explicit UTF-8 encoding\n",
    "    decode_error='ignore',  # Handle encoding errors gracefully\n",
    "    strip_accents='unicode',  # Handle accented characters\n",
    "    token_pattern=r'(?u)\\b\\w+\\b'  # Unicode-aware word boundaries\n",
    ")\n",
    "\n",
    "# Alternative configuration for word-based analysis (uncomment if preferred)\n",
    "# vectorizer = TfidfVectorizer(\n",
    "#     max_features=2000,\n",
    "#     stop_words=None,  # No stop words for multilingual support\n",
    "#     ngram_range=(1, 2),\n",
    "#     min_df=1,\n",
    "#     max_df=0.9,\n",
    "#     lowercase=True,\n",
    "#     encoding='utf-8',\n",
    "#     decode_error='ignore',\n",
    "#     strip_accents='unicode'\n",
    "# )\n",
    "\n",
    "# Fit and transform the text data\n",
    "X = vectorizer.fit_transform(data_clean['combined_text'])\n",
    "y = data_clean['level']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"Vectorizer encoding: {vectorizer.encoding}\")\n",
    "print(f\"Vectorizer analyzer: {vectorizer.analyzer}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c483f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree Classifier with GridSearch and Class Weighting...\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "\n",
      "Best Parameters found for Decision Tree:\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Decision Tree Accuracy: 0.7059\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.67      0.67      0.67         6\n",
      "          H2       0.83      0.71      0.77         7\n",
      "          H3       0.75      0.75      0.75         4\n",
      "          H4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.56      0.53      0.55        17\n",
      "weighted avg       0.75      0.71      0.73        17\n",
      "\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[4 1 0 1]\n",
      " [1 5 1 0]\n",
      " [1 0 3 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Classifier with GridSearch and Class Weighting...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "Best Parameters found for Random Forest:\n",
      "{'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "Random Forest Accuracy: 0.5882\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.60      0.50      0.55         6\n",
      "          H2       0.57      0.57      0.57         7\n",
      "          H3       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.59      0.61      0.59        17\n",
      "weighted avg       0.59      0.59      0.58        17\n",
      "\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[3 2 1 0]\n",
      " [2 4 1 0]\n",
      " [0 1 3 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "==================================================\n",
      "Model Comparison:\n",
      "Decision Tree Accuracy: 0.7059\n",
      "Random Forest Accuracy: 0.5882\n",
      "Accuracy Difference (RF - DT): -0.1176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================\n",
    "# 1. Decision Tree Classifier with GridSearchCV and class weighting\n",
    "# =============================================================\n",
    "print(\"Training Decision Tree Classifier with GridSearch and Class Weighting...\")\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Create a Decision Tree classifier with balanced class weights\n",
    "dt_classifier = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Address data imbalance\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV for Decision Tree\n",
    "dt_grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier,\n",
    "    param_grid=dt_param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best Decision Tree estimator\n",
    "best_dt = dt_grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Parameters found for Decision Tree:\")\n",
    "print(dt_grid_search.best_params_)\n",
    "\n",
    "# Make predictions with the best Decision Tree model\n",
    "dt_y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(f\"\\nDecision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_y_pred, zero_division=0))\n",
    "\n",
    "print(\"\\nDecision Tree Confusion Matrix:\")\n",
    "dt_cm = confusion_matrix(y_test, dt_y_pred, labels=np.unique(y))\n",
    "print(dt_cm)\n",
    "\n",
    "# =============================================================\n",
    "# 2. Random Forest Classifier with GridSearchCV and class weighting\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Random Forest Classifier with GridSearch and Class Weighting...\")\n",
    "\n",
    "# Define the parameter grid for Random Forest GridSearchCV\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier with balanced class weights\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Address data imbalance\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV for Random Forest\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best Random Forest estimator\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Parameters found for Random Forest:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "\n",
    "# Make predictions with the best Random Forest model\n",
    "rf_y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"\\nRandom Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred, zero_division=0))\n",
    "\n",
    "print(\"\\nRandom Forest Confusion Matrix:\")\n",
    "rf_cm = confusion_matrix(y_test, rf_y_pred, labels=np.unique(y))\n",
    "print(rf_cm)\n",
    "\n",
    "# =============================================================\n",
    "# 3. Compare the models\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Accuracy Difference (RF - DT): {rf_accuracy - dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab917003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# 4. Function to predict heading level for new title and text\n",
    "# =============================================================\n",
    "\n",
    "def predict_heading_level(title, text, vectorizer, model):\n",
    "    \"\"\"\n",
    "    Predict the heading level (H1, H2, H3, H4) for a given title and text\n",
    "\n",
    "    Args:\n",
    "        title (str): The heading text\n",
    "        text (str): The content under the heading\n",
    "        vectorizer: Fitted vectorizer used in training (e.g., TfidfVectorizer)\n",
    "        model: Trained classification model (e.g., best_rf)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (predicted_level, confidence_scores)\n",
    "    \"\"\"\n",
    "    # Combine title and text\n",
    "    combined_text = str(title) + ' ' + str(text)\n",
    "\n",
    "    # Transform the input using the trained vectorizer\n",
    "    text_features = vectorizer.transform([combined_text])\n",
    "\n",
    "    # Predict label\n",
    "    prediction = model.predict(text_features)[0]\n",
    "\n",
    "    # Predict confidence scores (probabilities)\n",
    "    probabilities = model.predict_proba(text_features)[0]\n",
    "    classes = model.classes_\n",
    "\n",
    "    # Map classes to probabilities\n",
    "    confidence_scores = dict(zip(classes, probabilities))\n",
    "\n",
    "    return prediction, confidence_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de45a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing the prediction function using best_rf:\n",
      "==================================================\n",
      "\n",
      "Example 1:\n",
      "Title: 'Introduction'\n",
      "Text: 'This document provides an overview of the foundation level extensions'\n",
      "Predicted Level: H1\n",
      "Confidence Scores: {'H1': 0.494875751950144, 'H2': 0.4076307288127603, 'H3': 0.09306494780852431, 'H4': 0.004428571428571429}\n",
      "\n",
      "Example 2:\n",
      "Title: 'Testing Methods'\n",
      "Text: 'Various testing approaches and methodologies used in software development'\n",
      "Predicted Level: H2\n",
      "Confidence Scores: {'H1': 0.3935607981888293, 'H2': 0.4446521956604157, 'H3': 0.15735843472218367, 'H4': 0.004428571428571429}\n",
      "\n",
      "Example 3:\n",
      "Title: 'Specific Implementation Details'\n",
      "Text: 'Detailed explanation of implementation steps and procedures'\n",
      "Predicted Level: H1\n",
      "Confidence Scores: {'H1': 0.48617563609843606, 'H2': 0.3697804555098211, 'H3': 0.1390439083917425, 'H4': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 5. Testing the function with examples\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing the prediction function using best_rf:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "examples = [\n",
    "    (\"Introduction\", \"This document provides an overview of the foundation level extensions\"),\n",
    "    (\"Testing Methods\", \"Various testing approaches and methodologies used in software development\"),\n",
    "    (\"Specific Implementation Details\", \"Detailed explanation of implementation steps and procedures\")\n",
    "]\n",
    "\n",
    "for idx, (title, text) in enumerate(examples, 1):\n",
    "    pred_level, conf_scores = predict_heading_level(title, text, vectorizer, best_rf)\n",
    "    print(f\"\\nExample {idx}:\")\n",
    "    print(f\"Title: '{title}'\")\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Predicted Level: {pred_level}\")\n",
    "    print(f\"Confidence Scores: {conf_scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "caa29e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the Decision Tree prediction function:\n",
      "--------------------------------------------------\n",
      "Title: 'Introduction'\n",
      "Text: 'This document provides an overview of the foundation level extensions'\n",
      "Predicted Level: H3\n",
      "Confidence Scores: {'H1': 0.0, 'H2': 0.0, 'H3': 1.0, 'H4': 0.0}\n",
      "\n",
      "Title: 'Testing Methods'\n",
      "Text: 'Various testing approaches and methodologies used in software development'\n",
      "Predicted Level: H1\n",
      "Confidence Scores: {'H1': 1.0, 'H2': 0.0, 'H3': 0.0, 'H4': 0.0}\n",
      "\n",
      "Title: 'Specific Implementation Details'\n",
      "Text: 'Detailed explanation of implementation steps and procedures'\n",
      "Predicted Level: H3\n",
      "Confidence Scores: {'H1': 0.0, 'H2': 0.0, 'H3': 1.0, 'H4': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Function to predict heading level using Decision Tree\n",
    "def predict_heading_level_dt(title, text):\n",
    "    \"\"\"\n",
    "    Predict the heading level (H1, H2, H3, H4) for given title and text using Decision Tree\n",
    "    \n",
    "    Args:\n",
    "        title (str): The title/heading text\n",
    "        text (str): The content text\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predicted_level, confidence_scores)\n",
    "    \"\"\"\n",
    "    # Combine title and text\n",
    "    combined_text = str(title) + ' ' + str(text)\n",
    "    \n",
    "    # Transform using the same vectorizer\n",
    "    text_features = vectorizer.transform([combined_text])\n",
    "    \n",
    "    # Predict using Decision Tree\n",
    "    prediction = best_dt.predict(text_features)[0]\n",
    "    \n",
    "    # Get prediction probabilities from Decision Tree\n",
    "    probabilities = best_dt.predict_proba(text_features)[0]\n",
    "    classes = best_dt.classes_\n",
    "    \n",
    "    # Create confidence scores dictionary\n",
    "    confidence_scores = dict(zip(classes, probabilities))\n",
    "    \n",
    "    return prediction, confidence_scores\n",
    "\n",
    "# Test the Decision Tree prediction function with some examples\n",
    "print(\"Testing the Decision Tree prediction function:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Example 1\n",
    "title1 = \"Introduction\"\n",
    "text1 = \"This document provides an overview of the foundation level extensions\"\n",
    "pred1, conf1 = predict_heading_level_dt(title1, text1)\n",
    "print(f\"Title: '{title1}'\")\n",
    "print(f\"Text: '{text1}'\")\n",
    "print(f\"Predicted Level: {pred1}\")\n",
    "print(f\"Confidence Scores: {conf1}\")\n",
    "print()\n",
    "\n",
    "# Example 2\n",
    "title2 = \"Testing Methods\"\n",
    "text2 = \"Various testing approaches and methodologies used in software development\"\n",
    "pred2, conf2 = predict_heading_level_dt(title2, text2)\n",
    "print(f\"Title: '{title2}'\")\n",
    "print(f\"Text: '{text2}'\")\n",
    "print(f\"Predicted Level: {pred2}\")\n",
    "print(f\"Confidence Scores: {conf2}\")\n",
    "print()\n",
    "\n",
    "# Example 3\n",
    "title3 = \"Specific Implementation Details\"\n",
    "text3 = \"Detailed explanation of implementation steps and procedures\"\n",
    "pred3, conf3 = predict_heading_level_dt(title3, text3)\n",
    "print(f\"Title: '{title3}'\")\n",
    "print(f\"Text: '{text3}'\")\n",
    "print(f\"Predicted Level: {pred3}\")\n",
    "print(f\"Confidence Scores: {conf3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0051662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔤 Testing Multilingual Capabilities for Heading Prediction\n",
      "============================================================\n",
      "\n",
      "1. 🌐 Language: ENGLISH\n",
      "   📝 Title: 'Chapter Introduction'\n",
      "   📄 Text : 'This chapter covers the basic concepts'\n",
      "   🔍 Predicted Level: H1\n",
      "   📊 Confidence: 0.554\n",
      "\n",
      "2. 🌐 Language: SPANISH\n",
      "   📝 Title: 'Introducción al Capítulo'\n",
      "   📄 Text : 'Este capítulo cubre los conceptos básicos'\n",
      "   🔍 Predicted Level: H1\n",
      "   📊 Confidence: 0.476\n",
      "\n",
      "3. 🌐 Language: FRENCH\n",
      "   📝 Title: 'Introduction du Chapitre'\n",
      "   📄 Text : 'Ce chapitre couvre les concepts de base'\n",
      "   🔍 Predicted Level: H1\n",
      "   📊 Confidence: 0.479\n",
      "\n",
      "4. 🌐 Language: GERMAN\n",
      "   📝 Title: 'Kapitel Einführung'\n",
      "   📄 Text : 'Dieses Kapitel behandelt die Grundkonzepte'\n",
      "   🔍 Predicted Level: H2\n",
      "   📊 Confidence: 0.472\n",
      "\n",
      "5. 🌐 Language: ACCENTED (ES)\n",
      "   📝 Title: 'Configuración Avanzada'\n",
      "   📄 Text : 'Configuración detallada de parámetros específicos'\n",
      "   🔍 Predicted Level: H2\n",
      "   📊 Confidence: 0.417\n",
      "\n",
      "6. 🌐 Language: EDGE CASE (Empty Title)\n",
      "   📝 Title: ''\n",
      "   📄 Text : 'What Colleges Say!'\n",
      "   🔍 Predicted Level: H1\n",
      "   📊 Confidence: 0.562\n",
      "\n",
      "7. 🌐 Language: MIXED LANGUAGE\n",
      "   📝 Title: 'API Documentation'\n",
      "   📄 Text : 'Documentation complète pour l'API REST'\n",
      "   🔍 Predicted Level: H1\n",
      "   📊 Confidence: 0.556\n",
      "\n",
      "8. 🌐 Language: JAPANESE\n",
      "   📝 Title: '章の紹介'\n",
      "   📄 Text : 'この章では基本的な概念について説明します'\n",
      "   🔍 Predicted Level: H1\n",
      "   📊 Confidence: 0.505\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔤 Testing Multilingual Capabilities for Heading Prediction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define multilingual examples\n",
    "examples = [\n",
    "    # English\n",
    "    (\"ENGLISH\", \"Chapter Introduction\", \"This chapter covers the basic concepts\"),\n",
    "    \n",
    "    # Spanish\n",
    "    (\"SPANISH\", \"Introducción al Capítulo\", \"Este capítulo cubre los conceptos básicos\"),\n",
    "    \n",
    "    # French\n",
    "    (\"FRENCH\", \"Introduction du Chapitre\", \"Ce chapitre couvre les concepts de base\"),\n",
    "    \n",
    "    # German\n",
    "    (\"GERMAN\", \"Kapitel Einführung\", \"Dieses Kapitel behandelt die Grundkonzepte\"),\n",
    "    \n",
    "    # Accented Spanish\n",
    "    (\"ACCENTED (ES)\", \"Configuración Avanzada\", \"Configuración detallada de parámetros específicos\"),\n",
    "    \n",
    "    # Empty title with text\n",
    "    (\"EDGE CASE (Empty Title)\", \"\", \"What Colleges Say!\"),\n",
    "    \n",
    "    # Mixed English + French\n",
    "    (\"MIXED LANGUAGE\", \"API Documentation\", \"Documentation complète pour l'API REST\"),\n",
    "    \n",
    "    # Japanese\n",
    "    (\"JAPANESE\", \"章の紹介\", \"この章では基本的な概念について説明します\")\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "for idx, (lang, title, text) in enumerate(examples, 1):\n",
    "    pred, conf = predict_heading_level(title, text, vectorizer, best_rf)\n",
    "    top_conf = max(conf.values())\n",
    "    print(f\"\\n{idx}. 🌐 Language: {lang}\")\n",
    "    print(f\"   📝 Title: '{title}'\")\n",
    "    print(f\"   📄 Text : '{text}'\")\n",
    "    print(f\"   🔍 Predicted Level: {pred}\")\n",
    "    print(f\"   📊 Confidence: {top_conf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c003f860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing multilingual capabilities:\n",
      "============================================================\n",
      "ENGLISH EXAMPLES:\n",
      "------------------------------\n",
      "EN Title: 'Chapter Introduction'\n",
      "EN Text: 'This chapter covers the basic concepts'\n",
      "Predicted: H1, Confidence: 1.000\n",
      "\n",
      "SPANISH EXAMPLES:\n",
      "------------------------------\n",
      "ES Title: 'Introducción al Capítulo'\n",
      "ES Text: 'Este capítulo cubre los conceptos básicos'\n",
      "Predicted: H2, Confidence: 1.000\n",
      "\n",
      "FRENCH EXAMPLES:\n",
      "------------------------------\n",
      "FR Title: 'Introduction du Chapitre'\n",
      "FR Text: 'Ce chapitre couvre les concepts de base'\n",
      "Predicted: H3, Confidence: 1.000\n",
      "\n",
      "GERMAN EXAMPLES:\n",
      "------------------------------\n",
      "DE Title: 'Kapitel Einführung'\n",
      "DE Text: 'Dieses Kapitel behandelt die Grundkonzepte'\n",
      "Predicted: H2, Confidence: 1.000\n",
      "\n",
      "ACCENTED CHARACTERS:\n",
      "------------------------------\n",
      "Accented Title: 'Configuración Avanzada'\n",
      "Accented Text: 'Configuración detallada de parámetros específicos'\n",
      "Predicted: H3, Confidence: 1.000\n",
      "\n",
      "TEST:\n",
      "------------------------------\n",
      "Accented Title: ''\n",
      "Accented Text: 'What Colleges Say!'\n",
      "Predicted: H1, Confidence: 1.000\n",
      "\n",
      "MIXED LANGUAGE:\n",
      "------------------------------\n",
      "Mixed Title: 'API Documentation'\n",
      "Mixed Text: 'Documentation complète pour l'API REST'\n",
      "Predicted: H3, Confidence: 1.000\n",
      "\n",
      "JAPANESE EXAMPLES:\n",
      "------------------------------\n",
      "JP Title: '章の紹介'\n",
      "JP Text: 'この章では基本的な概念について説明します'\n",
      "Predicted: H1, Confidence: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Test multilingual capabilities\n",
    "print(\"Testing multilingual capabilities:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# English examples\n",
    "print(\"ENGLISH EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_en1, conf_en1 = predict_heading_level_dt(\"Chapter Introduction\", \"This chapter covers the basic concepts\")\n",
    "print(f\"EN Title: 'Chapter Introduction'\")\n",
    "print(f\"EN Text: 'This chapter covers the basic concepts'\")\n",
    "print(f\"Predicted: {pred_en1}, Confidence: {max(conf_en1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Spanish examples\n",
    "print(\"SPANISH EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_es1, conf_es1 = predict_heading_level_dt(\"Introducción al Capítulo\", \"Este capítulo cubre los conceptos básicos\")\n",
    "print(f\"ES Title: 'Introducción al Capítulo'\")\n",
    "print(f\"ES Text: 'Este capítulo cubre los conceptos básicos'\")\n",
    "print(f\"Predicted: {pred_es1}, Confidence: {max(conf_es1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# French examples\n",
    "print(\"FRENCH EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_fr1, conf_fr1 = predict_heading_level_dt(\"Introduction du Chapitre\", \"Ce chapitre couvre les concepts de base\")\n",
    "print(f\"FR Title: 'Introduction du Chapitre'\")\n",
    "print(f\"FR Text: 'Ce chapitre couvre les concepts de base'\")\n",
    "print(f\"Predicted: {pred_fr1}, Confidence: {max(conf_fr1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# German examples\n",
    "print(\"GERMAN EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_de1, conf_de1 = predict_heading_level_dt(\"Kapitel Einführung\", \"Dieses Kapitel behandelt die Grundkonzepte\")\n",
    "print(f\"DE Title: 'Kapitel Einführung'\")\n",
    "print(f\"DE Text: 'Dieses Kapitel behandelt die Grundkonzepte'\")\n",
    "print(f\"Predicted: {pred_de1}, Confidence: {max(conf_de1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Test with accented characters\n",
    "print(\"ACCENTED CHARACTERS:\")\n",
    "print(\"-\" * 30)\n",
    "pred_acc, conf_acc = predict_heading_level_dt(\"Configuración Avanzada\", \"Configuración detallada de parámetros específicos\")\n",
    "print(f\"Accented Title: 'Configuración Avanzada'\")\n",
    "print(f\"Accented Text: 'Configuración detallada de parámetros específicos'\")\n",
    "print(f\"Predicted: {pred_acc}, Confidence: {max(conf_acc.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "print(\"TEST:\")\n",
    "print(\"-\" * 30)\n",
    "pred_acc2, conf_acc2 = predict_heading_level_dt(\" \", \"What Colleges Say!\")\n",
    "print(f\"Accented Title: ''\")\n",
    "print(f\"Accented Text: 'What Colleges Say!'\")\n",
    "print(f\"Predicted: {pred_acc2}, Confidence: {max(conf_acc2.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Test with mixed languages\n",
    "print(\"MIXED LANGUAGE:\")\n",
    "print(\"-\" * 30)\n",
    "pred_mix, conf_mix = predict_heading_level_dt(\"API Documentation\", \"Documentation complète pour l'API REST\")\n",
    "print(f\"Mixed Title: 'API Documentation'\")\n",
    "print(f\"Mixed Text: 'Documentation complète pour l'API REST'\")\n",
    "print(f\"Predicted: {pred_mix}, Confidence: {max(conf_mix.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Japanese examples\n",
    "print(\"JAPANESE EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_jp, conf_jp = predict_heading_level_dt(\"章の紹介\", \"この章では基本的な概念について説明します\")\n",
    "print(f\"JP Title: '章の紹介'\")\n",
    "print(f\"JP Text: 'この章では基本的な概念について説明します'\")\n",
    "print(f\"Predicted: {pred_jp}, Confidence: {max(conf_jp.values()):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a735358c",
   "metadata": {},
   "source": [
    "# 🐛 Document Processing Issue Analysis\n",
    "\n",
    "The enhanced Document Intelligence System is encountering a critical bug where PDF documents are being closed prematurely during processing. This is causing all 15 PDF files in Collection 2 to fail processing.\n",
    "\n",
    "## Issue Details:\n",
    "- **Error**: \"document closed\" occurring for all PDF files\n",
    "- **Root Cause**: Improper PDF document lifecycle management in the enhanced document processor\n",
    "- **Impact**: No documents are successfully processed, causing the system to exit\n",
    "\n",
    "## Solution Required:\n",
    "We need to fix the document processor to properly handle PDF document objects and ensure they remain open during the entire processing cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c8750",
   "metadata": {},
   "source": [
    "# 🔍 Root Cause Analysis\n",
    "\n",
    "**Issue Identified**: The `document closed` error is caused by premature closing of PDF documents in the processing pipeline.\n",
    "\n",
    "**Technical Details**:\n",
    "- The `process_document` method closes the PDF document after processing\n",
    "- However, the return statement happens after the `finally` block which tries to access `doc.page_count`\n",
    "- This creates a race condition where the document is accessed after being closed\n",
    "\n",
    "**Solution Strategy**:\n",
    "We need to create a completely isolated document processing approach where each document is processed in its own context without premature closing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
