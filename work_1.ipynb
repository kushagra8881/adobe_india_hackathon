{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b2f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cfe6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('output_outline_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22248aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>level</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>Revision History</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>Table of Contents</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>Acknowledgements</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>1. Introduction to the Foundation Level Extens...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0CCG5S312.json</td>\n",
       "      <td>Overview  Foundation Level Extensions</td>\n",
       "      <td>H1</td>\n",
       "      <td>2. Introduction to Foundation Level Agile Test...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H3</td>\n",
       "      <td>Social Media Campaigns</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H3</td>\n",
       "      <td>Influencer Partnerships</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H2</td>\n",
       "      <td>Traditional Marketing</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H1</td>\n",
       "      <td>Budget Allocation</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Z1QW23ER45.json</td>\n",
       "      <td>Marketing Plan: Product Launch 2025</td>\n",
       "      <td>H1</td>\n",
       "      <td>Performance Metrics</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file                                    title level  \\\n",
       "0    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "1    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "2    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "3    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "4    E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
       "..               ...                                      ...   ...   \n",
       "166  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H3   \n",
       "167  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H3   \n",
       "168  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H2   \n",
       "169  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H1   \n",
       "170  Z1QW23ER45.json      Marketing Plan: Product Launch 2025    H1   \n",
       "\n",
       "                                                  text  page  \n",
       "0                                    Revision History      2  \n",
       "1                                   Table of Contents      3  \n",
       "2                                    Acknowledgements      4  \n",
       "3    1. Introduction to the Foundation Level Extens...     5  \n",
       "4    2. Introduction to Foundation Level Agile Test...     6  \n",
       "..                                                 ...   ...  \n",
       "166                             Social Media Campaigns     7  \n",
       "167                            Influencer Partnerships     8  \n",
       "168                              Traditional Marketing     9  \n",
       "169                                  Budget Allocation    10  \n",
       "170                                Performance Metrics    12  \n",
       "\n",
       "[171 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db13ad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (171, 5)\n",
      "\n",
      "Column names: ['file', 'title', 'level', 'text', 'page']\n",
      "\n",
      "Unique levels: ['H1' 'H2' 'H3' 'H4']\n",
      "\n",
      "Level counts:\n",
      "level\n",
      "H2    72\n",
      "H1    59\n",
      "H3    36\n",
      "H4     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few rows:\n",
      "              file                                    title level  \\\n",
      "0  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "1  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "2  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "3  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "4  E0CCG5S312.json  Overview  Foundation Level Extensions      H1   \n",
      "\n",
      "                                                text  page  \n",
      "0                                  Revision History      2  \n",
      "1                                 Table of Contents      3  \n",
      "2                                  Acknowledgements      4  \n",
      "3  1. Introduction to the Foundation Level Extens...     5  \n",
      "4  2. Introduction to Foundation Level Agile Test...     6  \n"
     ]
    }
   ],
   "source": [
    "# Check data structure and unique levels\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"\\nColumn names:\", data.columns.tolist())\n",
    "print(\"\\nUnique levels:\", data['level'].unique())\n",
    "print(\"\\nLevel counts:\")\n",
    "print(data['level'].value_counts())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99561f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08770719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for Random Forest classification...\n",
      "Cleaned data shape: (166, 6)\n",
      "Level distribution after cleaning:\n",
      "level\n",
      "H2    70\n",
      "H1    57\n",
      "H3    35\n",
      "H4     4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2672484/1276247304.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['combined_text'] = data_clean['title'].astype(str) + ' ' + data_clean['text'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and feature engineering\n",
    "print(\"Preparing data for Random Forest classification...\")\n",
    "\n",
    "# Clean and prepare the data\n",
    "data_clean = data.dropna(subset=['title', 'text', 'level'])\n",
    "\n",
    "# Combine title and text for feature extraction\n",
    "data_clean['combined_text'] = data_clean['title'].astype(str) + ' ' + data_clean['text'].astype(str)\n",
    "\n",
    "# Remove empty or very short texts\n",
    "data_clean = data_clean[data_clean['combined_text'].str.len() > 3]\n",
    "\n",
    "print(f\"Cleaned data shape: {data_clean.shape}\")\n",
    "print(f\"Level distribution after cleaning:\")\n",
    "print(data_clean['level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cf11171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features using TF-IDF with multilingual support...\n",
      "Feature matrix shape: (166, 1593)\n",
      "Target variable shape: (166,)\n",
      "Vectorizer encoding: utf-8\n",
      "Vectorizer analyzer: char_wb\n",
      "Training set size: 149\n",
      "Testing set size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushagra/Documents/code/AI/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:555: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction using TF-IDF with multilingual UTF-8 support\n",
    "print(\"Extracting features using TF-IDF with multilingual support...\")\n",
    "\n",
    "# Create TF-IDF features from combined text with UTF-8 and multilingual support\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,  # Increased for multilingual content\n",
    "    ngram_range=(1, 3),  # Use unigrams, bigrams, and trigrams for better multilingual support\n",
    "    min_df=1,  # Reduced to handle diverse languages\n",
    "    max_df=0.9,  # Slightly increased threshold\n",
    "    lowercase=True,  # Convert to lowercase for consistency\n",
    "    analyzer='char_wb',  # Character-based analysis for multilingual support\n",
    "    encoding='utf-8',  # Explicit UTF-8 encoding\n",
    "    decode_error='ignore',  # Handle encoding errors gracefully\n",
    "    strip_accents='unicode',  # Handle accented characters\n",
    "    token_pattern=r'(?u)\\b\\w+\\b'  # Unicode-aware word boundaries\n",
    ")\n",
    "\n",
    "# Alternative configuration for word-based analysis (uncomment if preferred)\n",
    "# vectorizer = TfidfVectorizer(\n",
    "#     max_features=2000,\n",
    "#     stop_words=None,  # No stop words for multilingual support\n",
    "#     ngram_range=(1, 2),\n",
    "#     min_df=1,\n",
    "#     max_df=0.9,\n",
    "#     lowercase=True,\n",
    "#     encoding='utf-8',\n",
    "#     decode_error='ignore',\n",
    "#     strip_accents='unicode'\n",
    "# )\n",
    "\n",
    "# Fit and transform the text data\n",
    "X = vectorizer.fit_transform(data_clean['combined_text'])\n",
    "y = data_clean['level']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"Vectorizer encoding: {vectorizer.encoding}\")\n",
    "print(f\"Vectorizer analyzer: {vectorizer.analyzer}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c483f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree Classifier with GridSearch and Class Weighting...\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "\n",
      "Best Parameters found for Decision Tree:\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Decision Tree Accuracy: 0.7059\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.67      0.67      0.67         6\n",
      "          H2       0.83      0.71      0.77         7\n",
      "          H3       0.75      0.75      0.75         4\n",
      "          H4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.56      0.53      0.55        17\n",
      "weighted avg       0.75      0.71      0.73        17\n",
      "\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[4 1 0 1]\n",
      " [1 5 1 0]\n",
      " [1 0 3 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Classifier with GridSearch and Class Weighting...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "Best Parameters found for Random Forest:\n",
      "{'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "Random Forest Accuracy: 0.5882\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.60      0.50      0.55         6\n",
      "          H2       0.57      0.57      0.57         7\n",
      "          H3       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.59      0.61      0.59        17\n",
      "weighted avg       0.59      0.59      0.58        17\n",
      "\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[3 2 1 0]\n",
      " [2 4 1 0]\n",
      " [0 1 3 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "==================================================\n",
      "Model Comparison:\n",
      "Decision Tree Accuracy: 0.7059\n",
      "Random Forest Accuracy: 0.5882\n",
      "Accuracy Difference (RF - DT): -0.1176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================\n",
    "# 1. Decision Tree Classifier with GridSearchCV and class weighting\n",
    "# =============================================================\n",
    "print(\"Training Decision Tree Classifier with GridSearch and Class Weighting...\")\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Create a Decision Tree classifier with balanced class weights\n",
    "dt_classifier = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Address data imbalance\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV for Decision Tree\n",
    "dt_grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier,\n",
    "    param_grid=dt_param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best Decision Tree estimator\n",
    "best_dt = dt_grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Parameters found for Decision Tree:\")\n",
    "print(dt_grid_search.best_params_)\n",
    "\n",
    "# Make predictions with the best Decision Tree model\n",
    "dt_y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(f\"\\nDecision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_y_pred, zero_division=0))\n",
    "\n",
    "print(\"\\nDecision Tree Confusion Matrix:\")\n",
    "dt_cm = confusion_matrix(y_test, dt_y_pred, labels=np.unique(y))\n",
    "print(dt_cm)\n",
    "\n",
    "# =============================================================\n",
    "# 2. Random Forest Classifier with GridSearchCV and class weighting\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Random Forest Classifier with GridSearch and Class Weighting...\")\n",
    "\n",
    "# Define the parameter grid for Random Forest GridSearchCV\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier with balanced class weights\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Address data imbalance\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV for Random Forest\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best Random Forest estimator\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Parameters found for Random Forest:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "\n",
    "# Make predictions with the best Random Forest model\n",
    "rf_y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"\\nRandom Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred, zero_division=0))\n",
    "\n",
    "print(\"\\nRandom Forest Confusion Matrix:\")\n",
    "rf_cm = confusion_matrix(y_test, rf_y_pred, labels=np.unique(y))\n",
    "print(rf_cm)\n",
    "\n",
    "# =============================================================\n",
    "# 3. Compare the models\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Accuracy Difference (RF - DT): {rf_accuracy - dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab917003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# 4. Function to predict heading level for new title and text\n",
    "# =============================================================\n",
    "\n",
    "def predict_heading_level(title, text, vectorizer, model):\n",
    "    \"\"\"\n",
    "    Predict the heading level (H1, H2, H3, H4) for a given title and text\n",
    "\n",
    "    Args:\n",
    "        title (str): The heading text\n",
    "        text (str): The content under the heading\n",
    "        vectorizer: Fitted vectorizer used in training (e.g., TfidfVectorizer)\n",
    "        model: Trained classification model (e.g., best_rf)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (predicted_level, confidence_scores)\n",
    "    \"\"\"\n",
    "    # Combine title and text\n",
    "    combined_text = str(title) + ' ' + str(text)\n",
    "\n",
    "    # Transform the input using the trained vectorizer\n",
    "    text_features = vectorizer.transform([combined_text])\n",
    "\n",
    "    # Predict label\n",
    "    prediction = model.predict(text_features)[0]\n",
    "\n",
    "    # Predict confidence scores (probabilities)\n",
    "    probabilities = model.predict_proba(text_features)[0]\n",
    "    classes = model.classes_\n",
    "\n",
    "    # Map classes to probabilities\n",
    "    confidence_scores = dict(zip(classes, probabilities))\n",
    "\n",
    "    return prediction, confidence_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de45a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing the prediction function using best_rf:\n",
      "==================================================\n",
      "\n",
      "Example 1:\n",
      "Title: 'Introduction'\n",
      "Text: 'This document provides an overview of the foundation level extensions'\n",
      "Predicted Level: H1\n",
      "Confidence Scores: {'H1': 0.494875751950144, 'H2': 0.4076307288127603, 'H3': 0.09306494780852431, 'H4': 0.004428571428571429}\n",
      "\n",
      "Example 2:\n",
      "Title: 'Testing Methods'\n",
      "Text: 'Various testing approaches and methodologies used in software development'\n",
      "Predicted Level: H2\n",
      "Confidence Scores: {'H1': 0.3935607981888293, 'H2': 0.4446521956604157, 'H3': 0.15735843472218367, 'H4': 0.004428571428571429}\n",
      "\n",
      "Example 3:\n",
      "Title: 'Specific Implementation Details'\n",
      "Text: 'Detailed explanation of implementation steps and procedures'\n",
      "Predicted Level: H1\n",
      "Confidence Scores: {'H1': 0.48617563609843606, 'H2': 0.3697804555098211, 'H3': 0.1390439083917425, 'H4': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 5. Testing the function with examples\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing the prediction function using best_rf:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "examples = [\n",
    "    (\"Introduction\", \"This document provides an overview of the foundation level extensions\"),\n",
    "    (\"Testing Methods\", \"Various testing approaches and methodologies used in software development\"),\n",
    "    (\"Specific Implementation Details\", \"Detailed explanation of implementation steps and procedures\")\n",
    "]\n",
    "\n",
    "for idx, (title, text) in enumerate(examples, 1):\n",
    "    pred_level, conf_scores = predict_heading_level(title, text, vectorizer, best_rf)\n",
    "    print(f\"\\nExample {idx}:\")\n",
    "    print(f\"Title: '{title}'\")\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Predicted Level: {pred_level}\")\n",
    "    print(f\"Confidence Scores: {conf_scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "caa29e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the Decision Tree prediction function:\n",
      "--------------------------------------------------\n",
      "Title: 'Introduction'\n",
      "Text: 'This document provides an overview of the foundation level extensions'\n",
      "Predicted Level: H3\n",
      "Confidence Scores: {'H1': 0.0, 'H2': 0.0, 'H3': 1.0, 'H4': 0.0}\n",
      "\n",
      "Title: 'Testing Methods'\n",
      "Text: 'Various testing approaches and methodologies used in software development'\n",
      "Predicted Level: H1\n",
      "Confidence Scores: {'H1': 1.0, 'H2': 0.0, 'H3': 0.0, 'H4': 0.0}\n",
      "\n",
      "Title: 'Specific Implementation Details'\n",
      "Text: 'Detailed explanation of implementation steps and procedures'\n",
      "Predicted Level: H3\n",
      "Confidence Scores: {'H1': 0.0, 'H2': 0.0, 'H3': 1.0, 'H4': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Function to predict heading level using Decision Tree\n",
    "def predict_heading_level_dt(title, text):\n",
    "    \"\"\"\n",
    "    Predict the heading level (H1, H2, H3, H4) for given title and text using Decision Tree\n",
    "    \n",
    "    Args:\n",
    "        title (str): The title/heading text\n",
    "        text (str): The content text\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predicted_level, confidence_scores)\n",
    "    \"\"\"\n",
    "    # Combine title and text\n",
    "    combined_text = str(title) + ' ' + str(text)\n",
    "    \n",
    "    # Transform using the same vectorizer\n",
    "    text_features = vectorizer.transform([combined_text])\n",
    "    \n",
    "    # Predict using Decision Tree\n",
    "    prediction = best_dt.predict(text_features)[0]\n",
    "    \n",
    "    # Get prediction probabilities from Decision Tree\n",
    "    probabilities = best_dt.predict_proba(text_features)[0]\n",
    "    classes = best_dt.classes_\n",
    "    \n",
    "    # Create confidence scores dictionary\n",
    "    confidence_scores = dict(zip(classes, probabilities))\n",
    "    \n",
    "    return prediction, confidence_scores\n",
    "\n",
    "# Test the Decision Tree prediction function with some examples\n",
    "print(\"Testing the Decision Tree prediction function:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Example 1\n",
    "title1 = \"Introduction\"\n",
    "text1 = \"This document provides an overview of the foundation level extensions\"\n",
    "pred1, conf1 = predict_heading_level_dt(title1, text1)\n",
    "print(f\"Title: '{title1}'\")\n",
    "print(f\"Text: '{text1}'\")\n",
    "print(f\"Predicted Level: {pred1}\")\n",
    "print(f\"Confidence Scores: {conf1}\")\n",
    "print()\n",
    "\n",
    "# Example 2\n",
    "title2 = \"Testing Methods\"\n",
    "text2 = \"Various testing approaches and methodologies used in software development\"\n",
    "pred2, conf2 = predict_heading_level_dt(title2, text2)\n",
    "print(f\"Title: '{title2}'\")\n",
    "print(f\"Text: '{text2}'\")\n",
    "print(f\"Predicted Level: {pred2}\")\n",
    "print(f\"Confidence Scores: {conf2}\")\n",
    "print()\n",
    "\n",
    "# Example 3\n",
    "title3 = \"Specific Implementation Details\"\n",
    "text3 = \"Detailed explanation of implementation steps and procedures\"\n",
    "pred3, conf3 = predict_heading_level_dt(title3, text3)\n",
    "print(f\"Title: '{title3}'\")\n",
    "print(f\"Text: '{text3}'\")\n",
    "print(f\"Predicted Level: {pred3}\")\n",
    "print(f\"Confidence Scores: {conf3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0051662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî§ Testing Multilingual Capabilities for Heading Prediction\n",
      "============================================================\n",
      "\n",
      "1. üåê Language: ENGLISH\n",
      "   üìù Title: 'Chapter Introduction'\n",
      "   üìÑ Text : 'This chapter covers the basic concepts'\n",
      "   üîç Predicted Level: H1\n",
      "   üìä Confidence: 0.554\n",
      "\n",
      "2. üåê Language: SPANISH\n",
      "   üìù Title: 'Introducci√≥n al Cap√≠tulo'\n",
      "   üìÑ Text : 'Este cap√≠tulo cubre los conceptos b√°sicos'\n",
      "   üîç Predicted Level: H1\n",
      "   üìä Confidence: 0.476\n",
      "\n",
      "3. üåê Language: FRENCH\n",
      "   üìù Title: 'Introduction du Chapitre'\n",
      "   üìÑ Text : 'Ce chapitre couvre les concepts de base'\n",
      "   üîç Predicted Level: H1\n",
      "   üìä Confidence: 0.479\n",
      "\n",
      "4. üåê Language: GERMAN\n",
      "   üìù Title: 'Kapitel Einf√ºhrung'\n",
      "   üìÑ Text : 'Dieses Kapitel behandelt die Grundkonzepte'\n",
      "   üîç Predicted Level: H2\n",
      "   üìä Confidence: 0.472\n",
      "\n",
      "5. üåê Language: ACCENTED (ES)\n",
      "   üìù Title: 'Configuraci√≥n Avanzada'\n",
      "   üìÑ Text : 'Configuraci√≥n detallada de par√°metros espec√≠ficos'\n",
      "   üîç Predicted Level: H2\n",
      "   üìä Confidence: 0.417\n",
      "\n",
      "6. üåê Language: EDGE CASE (Empty Title)\n",
      "   üìù Title: ''\n",
      "   üìÑ Text : 'What Colleges Say!'\n",
      "   üîç Predicted Level: H1\n",
      "   üìä Confidence: 0.562\n",
      "\n",
      "7. üåê Language: MIXED LANGUAGE\n",
      "   üìù Title: 'API Documentation'\n",
      "   üìÑ Text : 'Documentation compl√®te pour l'API REST'\n",
      "   üîç Predicted Level: H1\n",
      "   üìä Confidence: 0.556\n",
      "\n",
      "8. üåê Language: JAPANESE\n",
      "   üìù Title: 'Á´†„ÅÆÁ¥π‰ªã'\n",
      "   üìÑ Text : '„Åì„ÅÆÁ´†„Åß„ÅØÂü∫Êú¨ÁöÑ„Å™Ê¶ÇÂøµ„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô'\n",
      "   üîç Predicted Level: H1\n",
      "   üìä Confidence: 0.505\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üî§ Testing Multilingual Capabilities for Heading Prediction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define multilingual examples\n",
    "examples = [\n",
    "    # English\n",
    "    (\"ENGLISH\", \"Chapter Introduction\", \"This chapter covers the basic concepts\"),\n",
    "    \n",
    "    # Spanish\n",
    "    (\"SPANISH\", \"Introducci√≥n al Cap√≠tulo\", \"Este cap√≠tulo cubre los conceptos b√°sicos\"),\n",
    "    \n",
    "    # French\n",
    "    (\"FRENCH\", \"Introduction du Chapitre\", \"Ce chapitre couvre les concepts de base\"),\n",
    "    \n",
    "    # German\n",
    "    (\"GERMAN\", \"Kapitel Einf√ºhrung\", \"Dieses Kapitel behandelt die Grundkonzepte\"),\n",
    "    \n",
    "    # Accented Spanish\n",
    "    (\"ACCENTED (ES)\", \"Configuraci√≥n Avanzada\", \"Configuraci√≥n detallada de par√°metros espec√≠ficos\"),\n",
    "    \n",
    "    # Empty title with text\n",
    "    (\"EDGE CASE (Empty Title)\", \"\", \"What Colleges Say!\"),\n",
    "    \n",
    "    # Mixed English + French\n",
    "    (\"MIXED LANGUAGE\", \"API Documentation\", \"Documentation compl√®te pour l'API REST\"),\n",
    "    \n",
    "    # Japanese\n",
    "    (\"JAPANESE\", \"Á´†„ÅÆÁ¥π‰ªã\", \"„Åì„ÅÆÁ´†„Åß„ÅØÂü∫Êú¨ÁöÑ„Å™Ê¶ÇÂøµ„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô\")\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "for idx, (lang, title, text) in enumerate(examples, 1):\n",
    "    pred, conf = predict_heading_level(title, text, vectorizer, best_rf)\n",
    "    top_conf = max(conf.values())\n",
    "    print(f\"\\n{idx}. üåê Language: {lang}\")\n",
    "    print(f\"   üìù Title: '{title}'\")\n",
    "    print(f\"   üìÑ Text : '{text}'\")\n",
    "    print(f\"   üîç Predicted Level: {pred}\")\n",
    "    print(f\"   üìä Confidence: {top_conf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c003f860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing multilingual capabilities:\n",
      "============================================================\n",
      "ENGLISH EXAMPLES:\n",
      "------------------------------\n",
      "EN Title: 'Chapter Introduction'\n",
      "EN Text: 'This chapter covers the basic concepts'\n",
      "Predicted: H1, Confidence: 1.000\n",
      "\n",
      "SPANISH EXAMPLES:\n",
      "------------------------------\n",
      "ES Title: 'Introducci√≥n al Cap√≠tulo'\n",
      "ES Text: 'Este cap√≠tulo cubre los conceptos b√°sicos'\n",
      "Predicted: H2, Confidence: 1.000\n",
      "\n",
      "FRENCH EXAMPLES:\n",
      "------------------------------\n",
      "FR Title: 'Introduction du Chapitre'\n",
      "FR Text: 'Ce chapitre couvre les concepts de base'\n",
      "Predicted: H3, Confidence: 1.000\n",
      "\n",
      "GERMAN EXAMPLES:\n",
      "------------------------------\n",
      "DE Title: 'Kapitel Einf√ºhrung'\n",
      "DE Text: 'Dieses Kapitel behandelt die Grundkonzepte'\n",
      "Predicted: H2, Confidence: 1.000\n",
      "\n",
      "ACCENTED CHARACTERS:\n",
      "------------------------------\n",
      "Accented Title: 'Configuraci√≥n Avanzada'\n",
      "Accented Text: 'Configuraci√≥n detallada de par√°metros espec√≠ficos'\n",
      "Predicted: H3, Confidence: 1.000\n",
      "\n",
      "TEST:\n",
      "------------------------------\n",
      "Accented Title: ''\n",
      "Accented Text: 'What Colleges Say!'\n",
      "Predicted: H1, Confidence: 1.000\n",
      "\n",
      "MIXED LANGUAGE:\n",
      "------------------------------\n",
      "Mixed Title: 'API Documentation'\n",
      "Mixed Text: 'Documentation compl√®te pour l'API REST'\n",
      "Predicted: H3, Confidence: 1.000\n",
      "\n",
      "JAPANESE EXAMPLES:\n",
      "------------------------------\n",
      "JP Title: 'Á´†„ÅÆÁ¥π‰ªã'\n",
      "JP Text: '„Åì„ÅÆÁ´†„Åß„ÅØÂü∫Êú¨ÁöÑ„Å™Ê¶ÇÂøµ„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô'\n",
      "Predicted: H1, Confidence: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Test multilingual capabilities\n",
    "print(\"Testing multilingual capabilities:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# English examples\n",
    "print(\"ENGLISH EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_en1, conf_en1 = predict_heading_level_dt(\"Chapter Introduction\", \"This chapter covers the basic concepts\")\n",
    "print(f\"EN Title: 'Chapter Introduction'\")\n",
    "print(f\"EN Text: 'This chapter covers the basic concepts'\")\n",
    "print(f\"Predicted: {pred_en1}, Confidence: {max(conf_en1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Spanish examples\n",
    "print(\"SPANISH EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_es1, conf_es1 = predict_heading_level_dt(\"Introducci√≥n al Cap√≠tulo\", \"Este cap√≠tulo cubre los conceptos b√°sicos\")\n",
    "print(f\"ES Title: 'Introducci√≥n al Cap√≠tulo'\")\n",
    "print(f\"ES Text: 'Este cap√≠tulo cubre los conceptos b√°sicos'\")\n",
    "print(f\"Predicted: {pred_es1}, Confidence: {max(conf_es1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# French examples\n",
    "print(\"FRENCH EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_fr1, conf_fr1 = predict_heading_level_dt(\"Introduction du Chapitre\", \"Ce chapitre couvre les concepts de base\")\n",
    "print(f\"FR Title: 'Introduction du Chapitre'\")\n",
    "print(f\"FR Text: 'Ce chapitre couvre les concepts de base'\")\n",
    "print(f\"Predicted: {pred_fr1}, Confidence: {max(conf_fr1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# German examples\n",
    "print(\"GERMAN EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_de1, conf_de1 = predict_heading_level_dt(\"Kapitel Einf√ºhrung\", \"Dieses Kapitel behandelt die Grundkonzepte\")\n",
    "print(f\"DE Title: 'Kapitel Einf√ºhrung'\")\n",
    "print(f\"DE Text: 'Dieses Kapitel behandelt die Grundkonzepte'\")\n",
    "print(f\"Predicted: {pred_de1}, Confidence: {max(conf_de1.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Test with accented characters\n",
    "print(\"ACCENTED CHARACTERS:\")\n",
    "print(\"-\" * 30)\n",
    "pred_acc, conf_acc = predict_heading_level_dt(\"Configuraci√≥n Avanzada\", \"Configuraci√≥n detallada de par√°metros espec√≠ficos\")\n",
    "print(f\"Accented Title: 'Configuraci√≥n Avanzada'\")\n",
    "print(f\"Accented Text: 'Configuraci√≥n detallada de par√°metros espec√≠ficos'\")\n",
    "print(f\"Predicted: {pred_acc}, Confidence: {max(conf_acc.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "print(\"TEST:\")\n",
    "print(\"-\" * 30)\n",
    "pred_acc2, conf_acc2 = predict_heading_level_dt(\" \", \"What Colleges Say!\")\n",
    "print(f\"Accented Title: ''\")\n",
    "print(f\"Accented Text: 'What Colleges Say!'\")\n",
    "print(f\"Predicted: {pred_acc2}, Confidence: {max(conf_acc2.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Test with mixed languages\n",
    "print(\"MIXED LANGUAGE:\")\n",
    "print(\"-\" * 30)\n",
    "pred_mix, conf_mix = predict_heading_level_dt(\"API Documentation\", \"Documentation compl√®te pour l'API REST\")\n",
    "print(f\"Mixed Title: 'API Documentation'\")\n",
    "print(f\"Mixed Text: 'Documentation compl√®te pour l'API REST'\")\n",
    "print(f\"Predicted: {pred_mix}, Confidence: {max(conf_mix.values()):.3f}\")\n",
    "print()\n",
    "\n",
    "# Japanese examples\n",
    "print(\"JAPANESE EXAMPLES:\")\n",
    "print(\"-\" * 30)\n",
    "pred_jp, conf_jp = predict_heading_level_dt(\"Á´†„ÅÆÁ¥π‰ªã\", \"„Åì„ÅÆÁ´†„Åß„ÅØÂü∫Êú¨ÁöÑ„Å™Ê¶ÇÂøµ„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô\")\n",
    "print(f\"JP Title: 'Á´†„ÅÆÁ¥π‰ªã'\")\n",
    "print(f\"JP Text: '„Åì„ÅÆÁ´†„Åß„ÅØÂü∫Êú¨ÁöÑ„Å™Ê¶ÇÂøµ„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô'\")\n",
    "print(f\"Predicted: {pred_jp}, Confidence: {max(conf_jp.values()):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a735358c",
   "metadata": {},
   "source": [
    "# üêõ Document Processing Issue Analysis\n",
    "\n",
    "The enhanced Document Intelligence System is encountering a critical bug where PDF documents are being closed prematurely during processing. This is causing all 15 PDF files in Collection 2 to fail processing.\n",
    "\n",
    "## Issue Details:\n",
    "- **Error**: \"document closed\" occurring for all PDF files\n",
    "- **Root Cause**: Improper PDF document lifecycle management in the enhanced document processor\n",
    "- **Impact**: No documents are successfully processed, causing the system to exit\n",
    "\n",
    "## Solution Required:\n",
    "We need to fix the document processor to properly handle PDF document objects and ensure they remain open during the entire processing cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c8750",
   "metadata": {},
   "source": [
    "# üîç Root Cause Analysis\n",
    "\n",
    "**Issue Identified**: The `document closed` error is caused by premature closing of PDF documents in the processing pipeline.\n",
    "\n",
    "**Technical Details**:\n",
    "- The `process_document` method closes the PDF document after processing\n",
    "- However, the return statement happens after the `finally` block which tries to access `doc.page_count`\n",
    "- This creates a race condition where the document is accessed after being closed\n",
    "\n",
    "**Solution Strategy**:\n",
    "We need to create a completely isolated document processing approach where each document is processed in its own context without premature closing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
